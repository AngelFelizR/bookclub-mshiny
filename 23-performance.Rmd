---
output: html_document
editor_options: 
  chunk_output_type: console
---
# Performance

> Transform your **poor performance prototype app** into a fast one capable of handling **thousands to tens of thousands of users simultaneously**.

**Learning Objectives**

- **Benchmark** your app using the **shinyloadtest** package to simulate multiple users.
- **Audit** your app with the **Google Lighthouse** node.js package to evaluate front-end performance.
- **Profile** your app to identify performance bottlenecks:
  - Use the **profvis** package to pinpoint slow R code.
  - Use **shiny.tictoc** JavaScript to measure:
    - *Time spent on server-side calculations*
    - *Time needed to recalculate outputs*
- **Optimize** your code by:
  - Moving data preparation code outside the app
  - Making the code faster
  - Caching reactives and outputs 
  - Applying psychological principles to make your app feel faster



## Dining at restaurant Shiny {-}

A Shiny app is like a restaurant where:

- Server $\approx$ Kitchen
- User $\approx$ Customer
- Request $\approx$ Order
- R process $\approx$ Chef

> But our chef is only can start a new order after ending the prior one (**single-threaded**), unless we make the event indepent to the main program flow by using **async programming** tecniques.


![](images/23-performance/01-Shiny-Server-Open-Source.webp)

## Making your chef more efficient {-}

- **Profiling**: Watching your chef when working to find the bottlenecks.
- **Optimising**: Brainstorming ways to help them work faster, like:
  - Hiring a prep cook who can come in before the first customer and chop some vegetables (prepares the data).
  - Invest in a time-saving gadget (a faster R package).
  - Adding more chefs (processes) to the restaurant (server).

![](images/23-performance/02-ShinyProxy.webp)


## Solving kitchen limitations {-}

If you keep hiring more chefs, eventually the kitchen (server) will get **too full**, so you have 2 alternatives:

- Adding more equipment (memory of cores) to **scale up**.
- Building more restaurants to **scale out**.

![](images/23-performance/03-scaling-alternatives.png){width="80%" height="80%"}


## Benchmarking {-}

I will help you figure out how many **users** each **process** can handle.

The [shinyloadtest](https://rstudio.github.io/shinyloadtest/) package and has three basic steps:

1. Record a script simulating a typical user with `shinyloadtest::record_session()`.

2. Replay the script with multiple simultaneous users with the **shinycannon** command-line tool.

3. Analyse the results using **shinyloadtest::report()**.


## Benchmarking: Recording {-}

1. Start your app from the terminal and copy the url that it gives you.

```bash
Rscript -e "shiny::runApp('examples/23-performance/Tabsets-App.R', port = 5555)"
```

2. Then paste the url into a `record_session()` call:

```r
shinyloadtest::record_session("http://127.0.0.1:5555")
```

3. On the new window, interact with the app to simulate a “typical” user, including pauses to reflect the thinking time that a real user would need.

4. Close the app, and shinyloadtest will save `recording.log` to your working directory.

5. Move the `recording.log` file to the folder to store the benchmark results.

```bash
mv recording.log examples/23-performance
```

## Benchmarking: Replay {-}

**shinycannon** is written in Java because the Java language is particularly well suited to the problem of performing tens or hundreds of web requests in parallel.

```bash
shinycannon examples/23-performance/recording.log http://127.0.0.1:5555 \
  --workers 1 \
  --loaded-duration-minutes 5 \
  --output-dir examples/23-performance/test_sessions/test1
```

```bash
shinycannon examples/23-performance/recording.log http://127.0.0.1:5555 \
  --workers 5 \
  --loaded-duration-minutes 5 \
  --output-dir examples/23-performance/test_sessions/test5
```

```bash
shinycannon examples/23-performance/recording.log http://127.0.0.1:5555 \
  --workers 10 \
  --loaded-duration-minutes 5 \
  --output-dir examples/23-performance/test_sessions/test10
```

## Benchmarking: Analysis {-}


```{r eval=FALSE}
BenchmarkData <- shinyloadtest::load_runs(
  `1 user` = "examples/23-performance/test_sessions/test1",
  `5 users` = "examples/23-performance/test_sessions/test5",
  `10 users` = "examples/23-performance/test_sessions/test10"
)
```

```{r eval=FALSE}
# If you getting errors related to gtable
# you can install this branch of dev version
# remotes::install_github("rstudio/shinyloadtest@gtable-error")

shinyloadtest::shinyloadtest_report(BenchmarkData, "examples/23-performance/report.html")
```

## Benchmarking: Analysis report {-}

<iframe id="serviceFrameSend" src="./examples/23-performance/report.html" width="950" height="600"  frameborder="0">


## Profiling: Example {-}

If your app is spending a lot of time calculating, you next need to figure out **which calculation** is slow.

```{r eval=FALSE}
library(profvis)

f <- function() {
  pause(0.2)
  g()
  h()
  10
}
g <- function() {
  pause(0.1)
  h()
}
h <- function() {
  pause(0.3)
}
```

## Profiling: Example {-}

Running `f()` mentally.

|**Initial state**|**Conceptual description**|
|:----------------|:-------------------------|
|`f()`
- `g()`
  - `h()`
- `h()` |f
f > g
f > g > h
f > h|


![](images/23-performance/04-flame-graph.png){width="80%" height="80%"}


## Profiling: R code {-}

```{r eval=FALSE}
profvis::profvis(f())
```

![](images/23-performance/05-flame-graph.png){width="80%" height="80%"}

## Profiling: Shiny App {-}

```{r eval=FALSE}
ui <- fluidPage(
  actionButton("x", "Push me"),
  textOutput("y")
)
server <- function(input, output, session) {
  output$y <- eventReactive(input$x, f())
}

# Note the explicit call to runApp() here: this is important
# as otherwise the app won't actually run.
profvis::profvis(runApp(shinyApp(ui, server)))
```

![](images/23-performance/06-flame-graph-shiny.png){width="80%" height="80%"}

### Tools

- profvis

The call stack and the "Flame graph"

```{r, eval = FALSE}
library(profvis)

f <- function() {
    pause(0.2)
  g()
    h()
    10
}
g <- function() {
    pause(0.1)
  h()
}
h <- function() {
    pause(0.3)
}

profvis::profvis(f())
```

Similar for {shiny}, but need explicit call to start the app (and close it with [Ctrl-C])

```{r, eval = FALSE}
ui <- fluidPage(
    actionButton("x", "Push me"),
      textOutput("y")
    )
server <- function(input, output, session) {
    output$y <- eventReactive(input$x, f())
}

app <- shinyApp(ui, server)
```

```{r, eval = FALSE}
profvis::profvis(
  shiny::runApp(
    app()
  )
)
```

Note that data downloads may not be tracked.

## Optimisation

### Cacheing

- `bindCache`
  - cacheing of any reactive value or render function
  - uses 'cache keys'
    - keep them as simple as possible
  - date/time-dependent results
  - cache has fixed size
  - scope (per session, or per process; in-memory or on-disk)

```{r, eval = FALSE}
r <- reactive(slow_function(input$x, input$y)) %>%
  bindCache(input$x, input$y)

output$text <- renderText(slow_function2(input$z)) %>%
  bindCache(input$z)
```

### Other Optimisations

- Do as little as possible
- Do your prep outside of the server
- Do your prep outside of shiny
- Use the fastest import method available
- Only do the slow stuff if requested
- Learn async programming

## Resources {-}


Good video
https://posit.co/resources/videos/profiling/

that are time-consuming to generate
many people are interested in checking the same data

- [Using Google Lighthouse for Web Pages](https://www.jumpingrivers.com/blog/shiny-app-start-up-google-lighthouse-part-1/)
- [https://rstudio.com/resources/rstudioconf-2019/shiny-in-production-principles-practices-and-tools/]()
- [https://rstudio.github.io/shinyloadtest/articles/analyzing-load-test-logs.html]()
- [https://queue.acm.org/detail.cfm?id=2927301]()
- [https://adv-r.hadley.nz/perf-improve.html]()
- [https://csgillespie.github.io/efficientR/]()
- [https://rstudio.com/resources/rstudioconf-2018/make-shiny-fast-by-doing-as-little-work-as-possible/]()
- [https://shiny.rstudio.com/articles/caching.html]()
- [https://shiny.rstudio.com/app-stories/weather-lookup-caching.html]()

- [https://www.appsilon.com/post/alternatives-to-scaling-shiny]()


## Meeting Videos {-}

### Cohort 1

`r knitr::include_url("https://www.youtube.com/embed/LLO6vDLqhWw")`

<details>
  <summary> Meeting chat log </summary>
  
```
00:07:09	Russ Hyde:	Hi
00:45:54	Robert Overman:	Are we having a session on shiny server?
01:01:58	docksbox@pm.me:	Thanks!
01:04:51	docksbox@pm.me:	Yes, sure
```
</details>

### Cohort 2

`r knitr::include_url("https://www.youtube.com/embed/UwrBxS39E3g")`


### Cohort 3

`r knitr::include_url("https://www.youtube.com/embed/GFbRR--E8Ow")`

<details>
  <summary>Meeting chat log</summary>
```
00:06:14	Brendan Lam:	What function records interactions with your Shiny app? How do you simulate users interacting with your app?
What is a flame graph and how do you interpret it?
What are the cache key and scope?
What are two ways of optimizing your app
00:09:25	Brendan Lam:	https://rstudio.github.io/promises/
00:14:39	Brendan Lam:	https://github.com/rstudio/shinycannon/issues/69#issuecomment-1322390215
00:22:46	Brendan Lam:	We start with f().
Then f() calls g(),
Then g() calls h().
Then f() calls h().
00:28:03	Brendan Lam:	https://memoise.r-lib.org/
00:38:16	Brendan Lam:	arrow::write_feather()
00:38:23	Brendan Lam:	arrow::read_feather()
00:38:30	Brendan Lam:	qs::qread()/qs::qsave() instead of readRDS()/saveRDS()
00:41:15	Brendan Lam:	https://rstudio.com/resources/rstudioconf-2019/shiny-in-production-principles-practices-and-tools/
https://rstudio.github.io/shinyloadtest/articles/analyzing-load-test-logs.html
https://queue.acm.org/detail.cfm?id=2927301
https://adv-r.hadley.nz/perf-improve.html
https://csgillespie.github.io/efficientR/
https://rstudio.com/resources/rstudioconf-2018/make-shiny-fast-by-doing-as-little-work-as-possible/
https://shiny.rstudio.com/articles/caching.html
https://shiny.rstudio.com/app-stories/weather-lookup-caching.html
00:45:15	Brendan Lam:	https://twitter.com/brendannathanl1
```
</details>


### Cohort 4

`r knitr::include_url("https://www.youtube.com/embed/bxSj2VdA8XI")`

<details>
  <summary>Meeting chat log</summary>
```
00:09:46	Trevin Flickinger:	start
00:15:04	Trevin Flickinger:	https://rstudio.github.io/shinyloadtest/articles/case-study-scaling.html
00:15:54	Trevin Flickinger:	https://posit.co/resources/videos/shiny-in-production-principles-practices-and-tools/
00:22:35	Trevin Flickinger:	https://rstudio.github.io/promises/
00:47:58	Matthew Efoli:	https://www.youtube.com/watch?v=hltOgAC2mC4&list=PLexAKolMzPcriOdeLwoMxQOyHRnMguEv4&index=28
00:50:44	Trevin Flickinger:	stop
```
</details>


### Cohort 5

`r knitr::include_url("https://www.youtube.com/embed/URL")`

<details>
  <summary>Meeting chat log</summary>
```
LOG
```
</details>
